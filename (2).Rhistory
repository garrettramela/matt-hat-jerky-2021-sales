git
knitr::opts_chunk$set(echo = TRUE)
require(devtools)
library(rmdformats)
library(fastDummies)
library(DataExplorer)
library(caret)
library(skimr)
library(RANN)
library(randomForest)
library(fastAdaboost)
library(gbm)
library(xgboost)
library(caretEnsemble)
library(C50)
library(earth)
library(wordcloud2)
# Read the data into RStudio & assign it to the 'sales' variable.
sales <- read.csv('sales_2021_YTD.csv')
# Take an initial look at the data frame fields, records, data types, etc. to see if anything seems off.
skimr::skim(sales)
summary(sales)
head(sales, 20)
DataExplorer::plot_intro(sales)
DataExplorer::plot_bar(sales)
uniqueTime <- unique(sales[1], incomparables = FALSE)
uniqueSalesChannel <- unique(sales[2], incomparables = FALSE)
uniqueCity <- unique(sales[3], incomparables = FALSE)
uniqueRegion <- unique(sales[4], incomparables = FALSE)
uniqueCountry <- unique(sales[5], incomparables = FALSE)
uniqueCustomerType <- unique(sales[6], incomparables = FALSE)
uniqueProductTitle <- unique(sales[7], incomparables = FALSE)
uniqueProductType <- unique(sales[8], incomparables = FALSE)
uniqueFields <- c(uniqueTime, uniqueSalesChannel, uniqueCity, uniqueRegion, uniqueCountry, uniqueCustomerType, uniqueProductTitle, uniqueProductType)
uniqueFields
install.packages("tidyverse")
install.packages("tidyverse")
cleanSales <- sales %>%
select(c('month', 'api_client','shipping_region'))
cleanSales <- sales %>%
dyplr::select(c('month', 'api_client','shipping_region'))
library(tidyverse)
cleanSales <- sales %>%
dyplr::select(c('month', 'api_client','shipping_region'))
cleanSales <- sales %>%
select(c('month', 'api_client','shipping_region'))
cleanSales <- sales %>%
select(c('month', 'api_client_title','shipping_region'))
cleanSales <- sales %>%
select(c('month','api_client_title','shipping_region','customer_type','product_title','orders','gross_sales','discounts','returns','net_sales','shipping','taxes','total_sales','total_tips','average_order_value'))
cleanSales <- sales %>%
select(c('month','api_client_title','shipping_region','customer_type','product_title','orders','gross_sales','discounts','returns','net_sales','shipping','taxes','total_sales','total_tips','average_order_value')) %>%
filter(sales, product_title != is.null())
cleanSales <- sales %>%
select(c('month','api_client_title','shipping_region','customer_type','product_title','orders','gross_sales','discounts','returns','net_sales','shipping','taxes','total_sales','total_tips','average_order_value')) %>%
filter(product_title != is.null())
cleanSales <- sales %>%
select(c('month','api_client_title','shipping_region','customer_type','product_title','orders','gross_sales','discounts','returns','net_sales','shipping','taxes','total_sales','total_tips','average_order_value'))
setwd("~/Downloads")
library(class)
# load data
uBank = read.csv('UniversalBank.csv', header = T)
head(uBank)
# The rate of accepting loan offer
length(which(uBank$Personal.Loan==1))/length(uBank$Personal.Loan)
# Split the data into three parts: Training, Validating, Testing
set.seed(123457)
N = length(uBank$Personal.Loan)
train.id = sort(sample(N, N*0.4))
v_t.id = seq(N)[-train.id]
N2 = length(v_t.id)
select = sample(N2, N2*0.5)
validate.id =sort(v_t.id[select])
test.id = sort(v_t.id[-select])
# Prepare input and output for the kNN model
train_input = scale(uBank[train.id, c(2,3,4,6,7,8,9,11,12,13,14)])
validate_input = scale(uBank[validate.id, c(2,3,4,6,7,8,9,11,12,13,14)])
test_input = scale(uBank[test.id, c(2,3,4,6,7,8,9,11,12,13,14)])
train_output = uBank[train.id, c(10)]
validate_output = uBank[validate.id, c(10)]
test_output = uBank[test.id, c(10)]
# Select k = 3
prediction_train = knn(train_input, train_input, train_output, k=3)
prediction_validate = knn(train_input, validate_input, train_output, k=3)
error_train = mean(abs(as.numeric(as.character(prediction_train))-train_output))
error_validate = mean(abs(as.numeric(as.character(prediction_validate))-validate_output))
# Error Rate Plot
error_train_list = seq(20)*0
error_validate_list = seq(20)*0
for(i in seq(20)){
prediction_train = knn(train_input, train_input, train_output, k=i)
prediction_validate = knn(train_input, validate_input, train_output, k=i)
error_train_list[i] = mean(abs(as.numeric(as.character(prediction_train))-train_output))
error_validate_list[i] = mean(abs(as.numeric(as.character(prediction_validate))-validate_output))
# Error Rate Plot
error_train_list = seq(20)*0
error_validate_list = seq(20)*0
for(i in seq(20)){
prediction_train = knn(train_input, train_input, train_output, k=i)
prediction_validate = knn(train_input, validate_input, train_output, k=i)
error_train_list[i] = mean(abs(as.numeric(as.character(prediction_train))-train_output))
error_validate_list[i] = mean(abs(as.numeric(as.character(prediction_validate))-validate_output))
}
plot(seq(20), error_train_list, col='blue', type='l', xlab='k', ylab='Error rate')
lines(seq(20), error_validate_list, col='red')
# Select k with the smallest error rate
which.min(error_validate_list)
# Predict Test Data
prediction_test = knn(train_input, test_input, train_output, k=3)
error_test = mean(abs(as.numeric(as.character(prediction_test))-test_output))
# Confusion Matrix
table(test_output, prediction_test)
# Confusion Matrix
table(test_output, prediction_test)
library(class)
# load data
uBank = read.csv('UniversalBank.csv', header = T)
head(uBank)
# The rate of accepting loan offer
length(which(uBank$Personal.Loan==1))/length(uBank$Personal.Loan)
# Split the data into three parts: Training, Validating, Testing
set.seed(123457)
N = length(uBank$Personal.Loan)
train.id = sort(sample(N, N*0.4))
v_t.id = seq(N)[-train.id]
N2 = length(v_t.id)
select = sample(N2, N2*0.5)
validate.id =sort(v_t.id[select])
test.id = sort(v_t.id[-select])
train_input = scale(uBank[train.id, c(2,3,4,6,7,8,9,11,12,13,14)])
validate_input = scale(uBank[validate.id, c(2,3,4,6,7,8,9,11,12,13,14)])
test_input = scale(uBank[test.id, c(2,3,4,6,7,8,9,11,12,13,14)])
train_output = uBank[train.id, c(10)]
validate_output = uBank[validate.id, c(10)]
test_output = uBank[test.id, c(10)]
train_input = scale(uBank[train.id, c(2,3,4,6,7,8,9,11,12,13,14)])
validate_input = scale(uBank[validate.id, c(2,3,4,6,7,8,9,11,12,13,14)])
test_input = scale(uBank[test.id, c(2,3,4,6,7,8,9,11,12,13,14)])
train_output = uBank[train.id, c(10)]
validate_output = uBank[validate.id, c(10)]
test_output = uBank[test.id, c(10)]
prediction_train = knn(train_input, train_input, train_output, k=3)
prediction_validate = knn(train_input, validate_input, train_output, k=3)
error_train = mean(abs(as.numeric(as.character(prediction_train))-train_output))
error_validate = mean(abs(as.numeric(as.character(prediction_validate))-validate_output))
error_train_list = seq(20)*0
error_validate_list = seq(20)*0
for(i in seq(20)){
prediction_train = knn(train_input, train_input, train_output, k=i)
prediction_validate = knn(train_input, validate_input, train_output, k=i)
error_train_list[i] = mean(abs(as.numeric(as.character(prediction_train))-train_output))
error_validate_list[i] = mean(abs(as.numeric(as.character(prediction_validate))-validate_output))
}
plot(seq(20), error_train_list, col='blue', type='l', xlab='k', ylab='Error rate')
lines(seq(20), error_validate_list, col='red')
which.min(error_validate_list)
prediction_test = knn(train_input, test_input, train_output, k=3)
error_test = mean(abs(as.numeric(as.character(prediction_test))-test_output))
table(test_output, prediction_test)
setwd("~/Downloads")
conversions <- read.csv("conversions-by-region.csv")
library(ggplot2)
cleanConversions <- conversions %>%
filter(location_country == "United States") %>%
filter(total_visitors >= 500 ) %>%
filter(total_conversion > .06) %>%
arrange(desc(total_conversion))
View(cleanConversions)
head(cleanConversions)
conversionChart <- ggplot(cleanConversions,
aes(x=location_region,
y=total_conversion)) +
geom_bar(stat="identity")
conversionChart
rlang::last_error()
rlang::last_trace()
library(dplyr)
library(ggplot2)
cleanConversions <- conversions %>%
filter(location_country == "United States") %>%
filter(total_visitors >= 500 ) %>%
filter(total_conversion > .06) %>%
arrange(desc(total_conversion))
View(cleanConversions)
head(cleanConversions)
conversionChart <- ggplot(cleanConversions,
aes(x=location_region,
y=total_conversion)) +
geom_bar(stat="identity")
View(conversions)
